{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be92fd2c6ebe8f23acc6dc0cb2c07bd6",
     "grade": false,
     "grade_id": "cell-c18d184342185ba6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.0.042025.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f98c572d6d128ba7804c8f53ed09a00",
     "grade": false,
     "grade_id": "cell-371f2ff64fb68763",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4 - Tree-based classification & Synthesis Project\n",
    "\n",
    "### Physiological Sensor Data Analysis (100 points)\n",
    "This synthesis project is based on a dataset of physiological sensor measurements collected from Smartphone based sensors. The original research sought to determine the particular activity of the subject based on the physiological measurements obtained from wearables and a SmartPhone. The physiological measurements were used to depict the test subject in one of four activities as follows:  \n",
    "   - neutral\n",
    "   - emotional\n",
    "   - mental\n",
    "   - physical  \n",
    " \n",
    "Your task will be to produce a model that, based on a limited number of features, returns the best possible estimate of the activity being performed by the test subject. While the original analysis utilized more advanced Machine Learning methods, we will concentrate on the supervised learning methods covered in this course.  \n",
    "\n",
    "The sensor dataset consists of 4480 rows, each with the subject ID, the activity label and 533 measurement features! Each of the 40 test volunteers were subjected to a series of 28 data collection events for each of the four activity types presented above. As you explore this data, you will find that the features are arranged by a particular measurement mode, each consisting of similar statistical values.  \n",
    "Before we get started, it will be necessary to ingest and prepare our data for training and testing purposes.  \n",
    "\n",
    "**Notes**  \n",
    " - Any available random_state or seed values should be initialized with an integer value of 42.\n",
    " - Some standard package imports have been provided below.\n",
    " - Additional import deemed necessary for your analysis can be added in the cell following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc91f37b36d6d7297bee00e2728b5cf6",
     "grade": false,
     "grade_id": "cell-8bfe1d8b1ee8cc6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1881ce1ea66591d5c3d01727a5dc1ab",
     "grade": false,
     "grade_id": "cell-93298b856670623e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# useful python standard libraries\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "\n",
    "# import core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpful SciKit-Learn libraries\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We will use this variable name multiple times\n",
    "base_feature_selector = \"_mad_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## suppress all warnings\n",
    "## uncomment only if necessary!\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "## Additional imports can be inlcuded here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a372dcf5b6566cb0ac683aa34035bc27",
     "grade": false,
     "grade_id": "cell-366227f52585e158",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1  (2 points)\n",
    "### Import CSV Sensor Data file\n",
    " - The first order of business is to read the data file, '_sensor_data.csv_ ', from the '_assets/_ ' folder.\n",
    " - Your function should accept zero arguments and return a Pandas DataFrame.\n",
    " - Be aware that the activity labels are in a format that may or may not work with your chosen models. If you choose to reassign the activity labels, use the following:  \n",
    "    - **'neutral' == 1**\n",
    "    - **'emotional' == 2**\n",
    "    - **'mental' == 3**\n",
    "    - **'physical' == 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0af85b93538e1924f3d8358fffc82893",
     "grade": false,
     "grade_id": "cell-323ce9af9affa7e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_sensor_data():\n",
    "    df = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    df=pd.read_csv(\"assets/sensor_data.csv\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore the data\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# get_sensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cafa248ec7ffea87343b6b6b44ba948",
     "grade": true,
     "grade_id": "cell-d56b92a082173913",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = get_sensor_data()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, pd.DataFrame\n",
    "), \"Q1: Your get_sensor_data function must return a Pandas DataFrame.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans.iloc[0][2], np.float64\n",
    "), \"Q1: The dtype of the first row, third column, is incorrect.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75c407c279f0d2c9b5193a07668eec0a",
     "grade": false,
     "grade_id": "cell-e309fa31d13a784b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2  (3 points)\n",
    "### Standard train_test_split\n",
    " - Our first exercise will be to produce a SciKit-Learn standard train/test split of a dataframe. In the following cell, complete the function that returns a standard train/test split of the sensor data.\n",
    "   - The function should accept a dataframe as produced by get_sensor_data() and a test_split value which defaults to 0.2.\n",
    "   - The function should return the standard X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce5eb4171a3dce8386d1757a61a45aba",
     "grade": false,
     "grade_id": "cell-bcd3c8cc8a52f6b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def std_train_test_split(df, test_split=0.2):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = (None,) * 4\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "#     if \"Subject_ID\" in df.columns and \"Activity_Label\" in df.columns:\n",
    "#         X=df.drop([\"Activity_Label\", \"Subject_ID\"], axis=1)\n",
    "#     elif \"Activity_Label\" in df.columns:\n",
    "#         X=df.drop(\"Activity_Label\", axis=1)\n",
    "#     else:\n",
    "#         X=df\n",
    "        \n",
    "    X_train, X_test, y_train, y_test=train_test_split(df.drop(\"Activity_Label\", axis=1), df[\"Activity_Label\"], \n",
    "                                                      test_size=test_split, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfd340819ecf4c92e5f2047e9adaf52f",
     "grade": true,
     "grade_id": "cell-aeeea8534654fbda",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "df = get_sensor_data()\n",
    "stu_ans = std_train_test_split(df)\n",
    "\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Q2: X_train should be a pd.DataFrame\"\n",
    "assert isinstance(stu_ans[2], pd.Series), \"Q2: y_train should be a pd.Series\"\n",
    "\n",
    "del stu_ans\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1971f4761e91c6750159276bc54449a",
     "grade": false,
     "grade_id": "cell-fca36043345da8b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3  (5 Points)\n",
    "### Build a baseline Tree model\n",
    "- Complete the following function that will establish a baseline score.  \n",
    "  - This function should retrieve and split the sensor data based on your previously constructed functions. Please use/default to, a split value of 0.2.  \n",
    "  - Using a _for loop_ or [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp), extract a list of feature names that includes the substring **base_feature_selector** defined in the **[library imports](#library-imports)** cell above.  \n",
    "  - Create a [DecisionTreeClassifier](https://scikit-learn.org/0.24/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) with default hyperparameters and the predetermined random_state value.\n",
    "    - Train this model on the features as extracted above.  \n",
    "  - Using the classifier's [score method](https://scikit-learn.org/0.24/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.score), score the model using X_test and the previously extracted subset of features.  \n",
    "  - Finally return a tuple consisting of the list of extracted features and score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45636a0e541b1b49ca824a8fc7ca5e3b",
     "grade": false,
     "grade_id": "cell-d0e06f1c335ec617",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_model_one():\n",
    "    score = None\n",
    "    feature_selector = base_feature_selector\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    df=get_sensor_data()\n",
    "    \n",
    "    features=[i for i in df.columns if feature_selector in i]\n",
    "    \n",
    "    df_features=pd.concat([df[features], df[\"Activity_Label\"]], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test=std_train_test_split(df_features)\n",
    "    \n",
    "    clf=DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    score=clf.score(X_test, y_test)\n",
    "    \n",
    "    return (features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ECG_original_mad_13',\n",
       "  'ECG_RR_window_mad_27',\n",
       "  'ECG_amplitude_RR_mad_41',\n",
       "  'ECG_HR_min_div_mad_55',\n",
       "  'ECG_hrv_mad_79',\n",
       "  'ECG_PSD_mad_93',\n",
       "  'ECG_p_VFL_mad_107',\n",
       "  'ECG_p_LF_mad_121',\n",
       "  'ECG_p_MF_mad_135',\n",
       "  'ECG_p_HF_mad_149',\n",
       "  'ECG_p_total_LF_mad_163',\n",
       "  'IT_Original_mad_187',\n",
       "  'IT_LF_mad_202',\n",
       "  'IT_RF_mad_217',\n",
       "  'IT_BRV_mad_233',\n",
       "  'IT_PSD_mad_247',\n",
       "  'IT_VLF_mad_261',\n",
       "  'IT_LF_mad_275',\n",
       "  'IT_MF_mad_289',\n",
       "  'IT_HF_mad_303',\n",
       "  'IT_p_Total_mad_317',\n",
       "  'EDA_Original_mad_338',\n",
       "  'EDA_processed_mad_352',\n",
       "  'EDA_Filt1_mad_366',\n",
       "  'EDA_Filt2_mad_380',\n",
       "  'EDA_Original_mad_442',\n",
       "  'EDA_processed_mad_456',\n",
       "  'EDA_Filt1_mad_470',\n",
       "  'EDA_Filt2_mad_484'],\n",
       " 0.8314732142857143)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this cell to observe your results\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "baseline_model_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa87efb37994822bc9030c6032c64feb",
     "grade": true,
     "grade_id": "cell-3a13464f8906cbe6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = baseline_model_one()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q3: Your function should return a tuple.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[0], list\n",
    "), \"Q3: Tuple element zero should be a list object.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Q3: Tuple element one should be a np.float64 value.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93d0b14658068d7e22d698cfb42dcf75",
     "grade": false,
     "grade_id": "cell-3cdcaa635d0d50b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 4  (3 Points)\n",
    "### Baseline Tree model questions\n",
    "1. Does the default accuracy score returned by the model seem reasonable to you; why or why not?\n",
    "2. What might be the problem with this model or with the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dbe07b3481fb5120d11957b6db24684",
     "grade": true,
     "grade_id": "cell-63d35379db6841e9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "The data incorporated by the model above was not supposed to have been split in the standard way, since the structure of the data is atypical i.e. it has 112 rows for each test subject (28 per activity/class) as opposed to 1 row per test subject, which means that some of the rows pertaining to a test subject could end up in the test set, while some could end up in the training set. Since the goal is to figure out which activity the test subject partakes to based on a certain subset of features, the data should be split by test subject with all the data pertaining to each of his activities sticking together since the multi-class classification model needs to be able understand the nuances of each feature under all conditions in order to optimally classify a test subject to a particular activity.\n",
    "\n",
    "That being said, I do not think the default accuracy score returned by the model seems reasonable. The passably good score of 0.83 is likely by chance or due to data leakage with a part of the training data (test subject data) being present in the test set, leading to a deceptively high score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "726fd2b82505c9f6220b41410cc97f68",
     "grade": false,
     "grade_id": "cell-6c9f9019196beec7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5  (10 Points)\n",
    "### A custom train_test_split function\n",
    " - Because of the nature of the original experiment's data collection methodology, the standard sklearn train_test_split() method cannot be applied successfully to this dataset. \n",
    " - The first significant task will be to create a 'custom_train_test_split()' function that will correctly separate train data from test data, given the structure of the data in the sensor dataset.  \n",
    " - Your function should accept two arguments:  \n",
    "   - A Pandas DataFrame such as returned by your get_sensor_data() function.\n",
    "   - An integer ___or___ float value that indicates the number of or percentage of the test data split.  \n",
    "   - Again, any random_state or seed values should be initialized with an integer value of 42.\n",
    " - Helpful Python Standard Libraries and functions:\n",
    "   - [random](https://docs.python.org/3/library/random.html)  \n",
    "     - random.seed()\n",
    "     - random.choices()\n",
    "   - [math](https://docs.python.org/3/library/math.html)  \n",
    "     - math.floor()  \n",
    "     - math.ceil()  \n",
    "  \n",
    " - Questions to keep in mind while creating this function:\n",
    "   - How might this function accept and use an integer or float value for the purpose of dividing the dataset?\n",
    "   - How do I ensure consistent random selection for reproducibility?\n",
    "   - Most importantly, how do I split this data to avoid one of the more devastating issues in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0eae343ccd98be2a6db576c621cbe199",
     "grade": false,
     "grade_id": "cell-1618476de514a891",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def custom_train_test_split(df=get_sensor_data(), test_split=0.2):\n",
    "    import math\n",
    "\n",
    "    X_train, X_test, y_train, y_test = (None,) * 4\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    random.seed(42)\n",
    "    \n",
    "#     df=get_sensor_data()\n",
    "    \n",
    "    n_sub=len(df.Subject_ID.unique())\n",
    "    \n",
    "    if type(test_split)==int:\n",
    "        n_test=test_split\n",
    "    else:\n",
    "        n_test=int(n_sub*test_split)\n",
    "        \n",
    "#     test_sub=random.sample(list(df.Subject_ID.unique()), n_test)\n",
    "      \n",
    "    test_sub=random.choices(list(df.Subject_ID.unique()), k=n_test)\n",
    "    \n",
    "    train_sub=[i for i in df.Subject_ID.unique() if i not in test_sub]\n",
    "\n",
    "    X_train=df.loc[df.Subject_ID.isin(train_sub)].drop(\"Activity_Label\", axis=1)\n",
    "    X_test=df.loc[df.Subject_ID.isin(test_sub)].drop(\"Activity_Label\", axis=1)\n",
    "    y_train=df.loc[df.Subject_ID.isin(train_sub), \"Activity_Label\"]\n",
    "    y_test=df.loc[df.Subject_ID.isin(test_sub), \"Activity_Label\"]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0176ef0792f9188d97a36b57e17580de",
     "grade": true,
     "grade_id": "cell-2c97a65714518e45",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "test_split = 5\n",
    "df = get_sensor_data()\n",
    "stu_ans = custom_train_test_split(df, test_split)\n",
    "\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Q4: X_train should be a pd.DataFrame\"\n",
    "assert isinstance(stu_ans[2], pd.Series), \"Q4: y_train should be a pd.Series\"\n",
    "assert len(stu_ans[1]) == 560, \"Q4: The length of your X_test dataframe is incorrect\"\n",
    "assert len(stu_ans[3]) == 560, \"Q4: The length of your y_test dataframe is incorrect\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1117fc11e889658359c54e46af3b93d1",
     "grade": false,
     "grade_id": "cell-7bdfb63c135245d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5, Part 2\n",
    "### Run a baseline_model using your custom data splitter\n",
    "- Copy/Paste your baseline model code from above into the function below.  \n",
    "  - Replace the std_train_test_split() function with your new custom_train_test_split().\n",
    "    - Use the default split of 0.2.\n",
    "  - Run this revised function and answer the questions below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6e7bbc7d2708012535b5a24edaf3272",
     "grade": false,
     "grade_id": "cell-f837ef40fcc382ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_model_two():\n",
    "    features, score = None, None\n",
    "    feature_selector = base_feature_selector\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    df=get_sensor_data()\n",
    "    \n",
    "    features=[i for i in df.columns if feature_selector in i]\n",
    "    \n",
    "#     df_features=pd.concat([df[features], df[\"Activity_Label\"]], axis=1)\n",
    "    \n",
    "    df_features=pd.concat([df[features], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test=custom_train_test_split(df_features)\n",
    "    \n",
    "    X_train.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    X_test.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    \n",
    "    clf=DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    score=clf.score(X_test, y_test)\n",
    "\n",
    "    return (features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ECG_original_mad_13',\n",
       "  'ECG_RR_window_mad_27',\n",
       "  'ECG_amplitude_RR_mad_41',\n",
       "  'ECG_HR_min_div_mad_55',\n",
       "  'ECG_hrv_mad_79',\n",
       "  'ECG_PSD_mad_93',\n",
       "  'ECG_p_VFL_mad_107',\n",
       "  'ECG_p_LF_mad_121',\n",
       "  'ECG_p_MF_mad_135',\n",
       "  'ECG_p_HF_mad_149',\n",
       "  'ECG_p_total_LF_mad_163',\n",
       "  'IT_Original_mad_187',\n",
       "  'IT_LF_mad_202',\n",
       "  'IT_RF_mad_217',\n",
       "  'IT_BRV_mad_233',\n",
       "  'IT_PSD_mad_247',\n",
       "  'IT_VLF_mad_261',\n",
       "  'IT_LF_mad_275',\n",
       "  'IT_MF_mad_289',\n",
       "  'IT_HF_mad_303',\n",
       "  'IT_p_Total_mad_317',\n",
       "  'EDA_Original_mad_338',\n",
       "  'EDA_processed_mad_352',\n",
       "  'EDA_Filt1_mad_366',\n",
       "  'EDA_Filt2_mad_380',\n",
       "  'EDA_Original_mad_442',\n",
       "  'EDA_processed_mad_456',\n",
       "  'EDA_Filt1_mad_470',\n",
       "  'EDA_Filt2_mad_484'],\n",
       " 0.6506696428571429)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine your new baseline_model() here\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "baseline_model_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff6e39cf17de5a2de70bfa628ea161d1",
     "grade": true,
     "grade_id": "cell-72944b90c520abfe",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = baseline_model_two()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q5: Your function should return a tuple.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[0], list\n",
    "), \"Q5: Tuple element zero should be a list object.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Q5: Tuple element one should be a np.float64 value.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd22eeb7592822938bfe25d6b616fedf",
     "grade": false,
     "grade_id": "cell-21809bc2608e0994",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6  (2 Points)\n",
    "### Custom train/test split questions\n",
    "Is the score of the model that incorporates custom_train_test_split() significantly different from the std_train_test_split() version? What issue(s) have we eliminated with our new custom_train_test_split() function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c97c9a253e5e8eec91e31911e863cd57",
     "grade": true,
     "grade_id": "cell-175bb32a2a2293c4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "The score of the model incorporating the custom_train_test_split() is significantly different (worse) than the one from the std_train_test_split() function, which seems more reasonable given the arbitary choice of features and the fact that there is no data leakage from the train set to the test set as seen in the standard split (which had led to a deceptively better score). The issues of not having all test subject data together in the dataset leading to data leakage has been resolved with the custom function. Moreover, by choosing test subjects in the custom split by incorporating the random.choices() function, we have made it possible for the model to be run on new as well as existing test subjects, which was not possible with the standard split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f897f7a3303926fd384f395925a77478",
     "grade": false,
     "grade_id": "cell-2e0f6b0e6c8930f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 7  (5 Points)\n",
    "### Confusion Matrix\n",
    " - We now want to better understand the relationship of correct and incorrect predictons made by a classification model. A very useful tool for examining a multiclass outcome, such as we have with our sensor dataset, is the [Confusion Matrix](https://scikit-learn.org/0.24/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    " - Using the SciKit-Learn [LogisticRegression](https://scikit-learn.org/0.24/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) model, create a function that returns a Confusion Matrix.\n",
    "   - Your function should accept zero arguments.  \n",
    "   - Set hyperparameter: max_iter=1000\n",
    "   - Any random_state or seed values should be initialized with an integer value of 42.\n",
    " - Use your previously defined functions to derive your train and test sets.\n",
    " - Scaling is an important factor in many Machine Learning projects (See section 3.3 in the course textbook). For the current dataset, use the sklearn method StandardScaler() to scale the train and test sets.\n",
    " - Using code that you had previously developed, include all features who's name includes the substring defined in \n",
    "**base_feature_selector** ([library imports](#library-imports)).\n",
    "- Your function should return the following tuple:  \n",
    "   - The confusion matrix array as returned by the sklean method confusion_matrix().  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "537ac6401b5c21173e3be37e770dea44",
     "grade": false,
     "grade_id": "cell-02b6f1ff73a7c6a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "def LR_confusion_matrix():\n",
    "\n",
    "    conf_matrix = None\n",
    "    feature_selector = base_feature_selector\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    df=get_sensor_data()\n",
    "    \n",
    "    features=[i for i in df.columns if feature_selector in i]\n",
    "    \n",
    "    df_features=pd.concat([df[features], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test=custom_train_test_split(df_features)\n",
    "    \n",
    "    X_train.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    X_test.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    \n",
    "    scaler=StandardScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "    \n",
    "    lr=LR(random_state=42, max_iter=1000)\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred=lr.predict(X_test_scaled)\n",
    "    \n",
    "    conf_matrix=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "971a142669c182f79a601b7608d981ed",
     "grade": true,
     "grade_id": "cell-9ce7903f9c06f5f5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = LR_confusion_matrix()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, np.ndarray\n",
    "), \"Q7: The second tuple element should be an np.ndarray\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc90b6ed8fc517f04eab3bafc225f48d",
     "grade": false,
     "grade_id": "cell-4c32db5c2bff0137",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8e666ad0ca9607d5bf7f7e7f59d246b",
     "grade": false,
     "grade_id": "cell-740465ee9e481736",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion():\n",
    "    cm = LR_confusion_matrix()\n",
    "    labels = {\"neutral\": 1, \"emotional\": 2, \"mental\": 3, \"physical\": 4}.keys()\n",
    "    display_cm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    display_cm.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view your confusion matrix here\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "plot_confusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75ea0791fb0a269cb8d9b3eaafdab63d",
     "grade": false,
     "grade_id": "cell-3a8431087ad8d20c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Question 8  (5 Points)\n",
    "### Basic Confusion Matrix Understanding\n",
    " - Answer the following questions concerning the above Confusion Matrix.  \n",
    " - Record (hardcode) your answers in the answer variables in the cell below for autograding purposes.  \n",
    " \n",
    "Q1. What is the number of __Correctly Predicted__ for the _mental_ activity?  \n",
    "Q2. How many __False Positive__ predictions were made for the _neutral_ activity?  \n",
    "Q3. How many __False Negative__ predictions were made for the _physical_ activity?  \n",
    "Q4. What is the __Precision__ Score for the _mental_ activity? (round to three decimal places)  \n",
    "Q5. What is the __Recall__ Score for the _emotional_ activity? (round to three decimal places)  \n",
    "Q6. What is the overall __Accuracy__ for the current model? (round to three decimal places)  \n",
    "Q7. Which activity is most confused for _mental_ activity when not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4798ae6588be5b458af88c00c90c8e2",
     "grade": false,
     "grade_id": "cell-aa8a1e16f3e1108a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Supply your answers to Q1 through Q7\n",
    "# in variables a1 through a7.\n",
    "\n",
    "# answers in case I use random.sample (without replacement)\n",
    "# a1 = 139\n",
    "# a2 = 51+30+14\n",
    "# a3 = 14+29+3\n",
    "# a4 = round((139/(139+7+9+3)), 3)\n",
    "# a5 = round((148/(148+51+9+16)), 3)\n",
    "# a6 = round(((96+148+139+178)/(96+118+7+3+51+148+9+16+30+51+139+4+14+29+3+178)), 3)\n",
    "# a7 = \"emotional\"\n",
    "\n",
    "# answers in case I use random.choices (with replacement)\n",
    "a1 = 152\n",
    "a2 = 91+31+27\n",
    "a3 = 27+3\n",
    "a4 = round((152/(152+10+1)), 3)\n",
    "a5 = round((99/(99+91+1+33)), 3)\n",
    "a6 = round(((155+99+152+194)/(155+55+10+4+91+99+1+33+31+36+152+5+27+3+194)), 3)\n",
    "a7 = \"emotional\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "stu_ans = (a1, a2, a3, a4, a5, a6, a7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cf126236594f1f8b63abf1dbe466506",
     "grade": true,
     "grade_id": "cell-6c520b1fae9d0a50",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == 7\n",
    "), \"Q8: Your answer tuple does not contain the correct number of answers.\"\n",
    "assert isinstance(stu_ans[0], int), \"Q8: Answer one should be an integer\"\n",
    "assert isinstance(stu_ans[1], int), \"Q8: Answer two should be an integer\"\n",
    "assert isinstance(stu_ans[2], int), \"Q8: Answer three should be an integer\"\n",
    "assert isinstance(stu_ans[3], float), \"Q8: Answer four should be a float\"\n",
    "assert isinstance(stu_ans[4], float), \"Q8: Answer five should be a float\"\n",
    "assert isinstance(stu_ans[5], float), \"Q8: Answer six should be a float\"\n",
    "assert isinstance(stu_ans[6], str), \"Q8: Answer seven should be a string\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a712696fa3a15efeae3e22251419927e",
     "grade": false,
     "grade_id": "cell-1aeefba857843791",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 9  (5 Points)\n",
    "### Feature Importance part 1\n",
    "#### Now we want to explore how some models are able to provide additional insight into the features that played a prominent role in the estimation outcome. \n",
    " - Produce a function that implements a RandomForestClassifier model, which includes the [**feature_importances_**](https://scikit-learn.org/0.24/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_) attribute.\n",
    "- The function accepts a single argument for the top X number of features, the default value will be 10.\n",
    "  - The classifier should use only two parameters:\n",
    "    - random_state=42\n",
    "    - n_jobs=-1\n",
    "- Use your previously defined functions to derive your train and test sets.\n",
    "- Using code that you had previously developed, include all features who's name includes the substring defined by **base_feature_selector** ([library imports](#library-imports)).\n",
    " - The function should return a tuple of two elements.\n",
    "   - The first element will be a **sorted** list of tuples in the form **\\[('feature_name', importance_value),...\\]**. The list of tuples should be sorted in descending order.\n",
    "     - This list of tuples should be sorted in **descending order** of feature_importance.\n",
    "   - The second element (test data score) should be an np.float64 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c720e8c74a6dea2ccee633e0265723f",
     "grade": false,
     "grade_id": "cell-ffe4926e6361f5fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_top_features(top=10):\n",
    "    top_x, score = None, None\n",
    "    feature_selector = base_feature_selector\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    df=get_sensor_data()\n",
    "    \n",
    "    features=[i for i in df.columns if feature_selector in i]\n",
    "    \n",
    "    df_features=pd.concat([df[features], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test=custom_train_test_split(df_features)\n",
    "    \n",
    "    X_train.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    X_test.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    \n",
    "    rfc=RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    list_of_tuples=list(zip(X_train.columns, rfc.feature_importances_))\n",
    "    sorted_list_of_tuples=sorted(list_of_tuples, key=lambda x: x[1], reverse=True)\n",
    "    top_x=sorted_list_of_tuples[:top]\n",
    "    \n",
    "    score=rfc.score(X_test, y_test)\n",
    "\n",
    "    return top_x, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review your results here\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# get_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4ec8635146881be9f78aee493f1817a",
     "grade": true,
     "grade_id": "cell-b112a369a5bef4a9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = get_top_features()\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == 2\n",
    "), \"Q9: Your answer tuple does not contain the correct number of elements.\"\n",
    "\n",
    "assert isinstance(stu_ans[0], list), \"Q9: The first tuple element should be a list\"\n",
    "\n",
    "assert len(stu_ans[0]) == 10, \"Q9: The default number of top features is not correct.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Q9: get_top_features() second return element should be an np.float64.\"\n",
    "\n",
    "del stu_ans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aab0db2fca3608134f1de4df4e532238",
     "grade": false,
     "grade_id": "cell-0562af8e13d94e4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 10  (10 Points)\n",
    "### Feature Importance part 2\n",
    "#### The value of Feature Importance \n",
    "- This follow-on question will use the same **RandomForestClassifier** model as in your get_top_features() function.\n",
    "- The new model will use a portion of the output returned by the get_top_features() function.\n",
    "- Use the previously defined functions to derive your train and test datasets.\n",
    "- Create a loop that trains your model with an incrementally increasing number of features from the top features list.\n",
    "  - The first pass will include the topmost important feature, the second pass will include the top two most important features and so on until the final pass of all top X features.\n",
    "- Your function should return a list of feature-based test data scores produced by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c60dd666af9160639df3e8dfbb0461e2",
     "grade": false,
     "grade_id": "cell-61533567ca475486",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def score_top_features(top=10):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    df=get_sensor_data()\n",
    "    \n",
    "    top_x, score=get_top_features(top)\n",
    "    \n",
    "    features=[]\n",
    "    for i in range(len(top_x)):\n",
    "        \n",
    "        features.append(top_x[i][0])\n",
    "        df_features=pd.concat([df[features], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "\n",
    "        X_train, X_test, y_train, y_test=custom_train_test_split(df=df_features)\n",
    "        \n",
    "        X_train.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "        X_test.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "        \n",
    "        rfc=RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        \n",
    "        scores.append(rfc.score(X_test, y_test))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review your top features results here\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# score_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08558c7df20da2d92a12150be64857c1",
     "grade": true,
     "grade_id": "cell-bbade458d0c15e25",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "top = 10\n",
    "stu_ans = score_top_features(top)\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == top\n",
    "), \"Q10: Your function does not return the correct number of scores.\"\n",
    "\n",
    "assert all(\n",
    "    isinstance(x, np.float64) for x in stu_ans\n",
    "), \"Q10: One or more of the returned scores is of an incorrect type.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7739a009138832617bb5f11238ce4fe",
     "grade": false,
     "grade_id": "cell-8fe2a304ac06b8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_scores(top=10):\n",
    "\n",
    "    if top > 29:\n",
    "        top = 29\n",
    "\n",
    "    top_x_features, score = get_top_features(top)\n",
    "    scores = score_top_features(top)\n",
    "\n",
    "    importance_scores = [score[1] for score in top_x_features]\n",
    "    x_axis = np.arange(1, len(scores) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.plot(x_axis, scores, label=\"Accuracy Score\", c=\"g\", linestyle=\"solid\")\n",
    "    plt.plot(\n",
    "        x_axis,\n",
    "        importance_scores,\n",
    "        label=\"Feature Importance Scores\",\n",
    "        c=\"r\",\n",
    "        linestyle=\"solid\",\n",
    "    )\n",
    "    plt.axhline(\n",
    "        score,\n",
    "        label=f\"All '{base_feature_selector}' features score\",\n",
    "        c=\"b\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "\n",
    "    plt.xticks(x_axis)\n",
    "    plt.ylim([0, max(score, max(importance_scores)) + 0.05])\n",
    "    plt.xlabel(\"Number of Top 10 Features Used\")\n",
    "    plt.ylabel(\"Score Value\")\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f32afade86587c02514ee243b8be7bf",
     "grade": false,
     "grade_id": "cell-616a3443dbb1643b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Scores Plot\n",
    "The plot_scores() function accepts top X features argumnet which defaults to a value of 10. Feel free to change the argument to better see how accuracy is affected by the number of top features used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs feature importance\n",
    "# the plot_scores() function will accept a\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48735e57990836244788501440628e19",
     "grade": false,
     "grade_id": "cell-4e84ab0e7aaf6f51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 11  (50 Points)\n",
    "### Final project\n",
    "- The final question for this assignment is open-ended with only a few **constraints**. Using any of the Supervised Machine Learning techniques and models presented in this course, produce a model that produces a best-possible ROC-AUC score. Your Question 11 award points will be evaluated solely on this score. The primary constraint for this question is that you will be able to utilize not more than **10** of the 533 available data features in the training and scoring of your model. A quick calculation of the number of available combinations C(n, r) = C(533, 10) = $\\frac{n!}{r!(n-r)!}$ = 4.684e20. That is very large number of possible combinations (the number of permutations is even greater)! Because of the intractability of checking all possible 10-feature combinations, it will be necessary to devise a scheme whereby your algorithm makes a selection of features and scores that selection. Be creative but also efficient in your feature selection process. Because multiple feature selection cycles may be necessary, you will also need to develop an efficient method of keeping track of the top model, features, and score.  \n",
    "\n",
    "- Why would we want to limit the number of features? \n",
    "   1. The creator of the project may want to minimize the number of sensors/measurements required to move the project forward.\n",
    "   2. The final product will be used on a smartphone where resource consumption is always a concern.\n",
    "   3. Computational resource availability of the development environment could be constrained due to budget availability.\n",
    "   4. The development environment may be intentionally constrained to mimic the production environment.\n",
    "  \n",
    "- You will find that even with these limitations, some model choices will still consume significant resources, even to the point of crashing the Python kernel!  \n",
    "\n",
    "- The activity_model() function:\n",
    "  - Arguments: none\n",
    "  - Use your previously defined functions to derive your train and test sets.\n",
    "  - If feasible, expand upon your previously created feature selection code.\n",
    "  - Use the following parameters when establishing your [roc_auc_score](https://scikit-learn.org/0.24/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) method:\n",
    "    - average=\"macro\"\n",
    "    - multi_class=\"ovr\"\n",
    "  - return: a tuple consisting of (fit_model, feature_list, roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d13d8ecd713b4ed9d58940ec96042792",
     "grade": false,
     "grade_id": "cell-aa54eef9e0c09556",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def activity_model():\n",
    "    model, features, score = (None,) * 3\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    # import classifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # set random seed\n",
    "    random.seed(42)\n",
    "    \n",
    "    df=get_sensor_data()\n",
    "    \n",
    "    # define required functions with roc_auc scoring\n",
    "    def get_top_features(top, df=get_sensor_data()):\n",
    "\n",
    "        X_train, X_test, y_train, y_test=custom_train_test_split(df)\n",
    "        X_train.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "        X_test.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "        rfc=RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        list_of_tuples=list(zip(X_train.columns, rfc.feature_importances_))\n",
    "        sorted_list_of_tuples=sorted(list_of_tuples, key=lambda x: x[1], reverse=True)\n",
    "        top_x=sorted_list_of_tuples[:top]\n",
    "        y_pred=rfc.predict_proba(X_test)\n",
    "        score=roc_auc_score(y_test, y_pred, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "        return top_x, score\n",
    "    \n",
    "    def get_top_feature_names(top_x):\n",
    "        \n",
    "        selected_features=[]\n",
    "        for i in range(len(top_x)):\n",
    "            selected_features.append(top_x[i][0])\n",
    "            \n",
    "        return selected_features\n",
    "    \n",
    "    # get top 100 features from the total 533\n",
    "    top_100, scores_100=get_top_features(top=100)\n",
    "    features_100=get_top_feature_names(top_100)\n",
    "    \n",
    "    # get top 50 features from the top 100\n",
    "    df_features_100=pd.concat([df[features_100], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "    top_50, scores_50=get_top_features(50, df=df_features_100)\n",
    "    features_50=get_top_feature_names(top_50)\n",
    "    \n",
    "    # get top 10 features from the top 50\n",
    "    df_features_50=pd.concat([df[features_50], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "    top_10, scores_10=get_top_features(10, df=df_features_50)\n",
    "    features_10=get_top_feature_names(top_10)\n",
    "    \n",
    "    # train the final model with the top 10 features\n",
    "    df_features_10=pd.concat([df[features_10], df[\"Activity_Label\"], df[\"Subject_ID\"]], axis=1)\n",
    "    X_train, X_test, y_train, y_test=custom_train_test_split(df=df_features_10)\n",
    "    X_train.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    X_test.drop(\"Subject_ID\", axis=1, inplace=True)\n",
    "    rfc=RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred=rfc.predict_proba(X_test)\n",
    "    \n",
    "    model=rfc\n",
    "    features=features_10\n",
    "    score=roc_auc_score(y_test, y_pred, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "    return (model, features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review your activity_model() return here\n",
    "# remember to comment the function call before submitting the notebook\n",
    "\n",
    "# activity_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a6b9f898c212bef7bb6bdd2f2b48205",
     "grade": true,
     "grade_id": "cell-b75d744376ca0a86",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden autograder model validation\n",
    "# test for AUC score >= 0.83\n",
    "\n",
    "stu_ans = activity_model()\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.83\n",
    "), f\"Q11: Your test AUC {stu_ans[2]:.4f} is less than 0.83. You will not receive any points for this question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd9f10b623502320ec1c62f8fc071d44",
     "grade": true,
     "grade_id": "cell-51c43ad464c6a07b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.85\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.85\n",
    "), f\"Q11: Your test AUC {stu_ans[2]:.4f} is less than 0.85. You will receive 25 points for this question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef17cb93c66df1dc0a1586b95ac65471",
     "grade": true,
     "grade_id": "cell-8013377ff7931f48",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.87\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.87\n",
    "), f\"Q11: Your test AUC {stu_ans[2]:.4f} is less than 0.87. You will receive 30 points for this question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "673cff6f549ebe345a23f8d2e5c0f31c",
     "grade": true,
     "grade_id": "cell-ebe32e8d5f5255f4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.89\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.89\n",
    "), f\"Q11: Your test AUC {stu_ans[2]:.4f} is less than 0.89. You will receive 35 points for this question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26ba8748ac588697dd3a58f942dc3cec",
     "grade": true,
     "grade_id": "cell-ee59bccdda8ea14c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.91\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.91\n",
    "), f\"Q11: Your test AUC {stu_ans[2]:.4f} is less than 0.91. You will receive 45 points for this question.\"\n",
    "\n",
    "del stu_ans"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
