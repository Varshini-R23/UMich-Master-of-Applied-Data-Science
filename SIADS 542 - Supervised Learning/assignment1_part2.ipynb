{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daa5a49ec1e1d1e18096d760097d2863",
     "grade": false,
     "grade_id": "cell-1262282752ee17cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b366bbef6251ec4b5104563adca51a00",
     "grade": false,
     "grade_id": "cell-cf5099926e9f16fa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 1 Part 2: Introduction to Supervised Machine Learning\n",
    "In this assignment you will be using the [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) dataset to create a classifier that can help diagnose patients. We chose this data not only because it provides a good basis for a kNN classification problem, but also because it illustrates one of the built-in datasets that comes with `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0c30abca2adbc632576a2d0ac12b13d",
     "grade": false,
     "grade_id": "cell-7696bde2345190bb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import some necessary libararies \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset from scikit-learn. To see a description of the dataset, uncomment the print statement\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfb14346b27d991a4c739154e05d99ff",
     "grade": false,
     "grade_id": "cell-fa8993b2db96f976",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The object returned by `load_breast_cancer()` is a scikit-learn `Bunch` object, which is similar to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can take a look at what essential attributes it has. Feel free to explore this object yourself. \n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7837834a64c60a4a751075f41dcea3bc",
     "grade": false,
     "grade_id": "cell-5192a5893e9a8115",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 0. Warm-up (5 pts)\n",
    "\n",
    "Understanding how many features you're dealing with and what each feature represents is an essential first step in machine learning.  So, how many features are there in this dataset? Complete the function below to return the answer as an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b569eb8bda25f1b9fe7e972cb5503792",
     "grade": false,
     "grade_id": "cell-0562c45651419b03",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_zero():\n",
    "    \"\"\"\n",
    "    This function returns the number of features of the breast cancer dataset as an integer. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    return cancer[\"data\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94753e2d4714bd8a0aac53529f82a9a",
     "grade": true,
     "grade_id": "cell-919dd7f0bfcbfd9a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a9f11e9a1043924800a48d69e643a9a",
     "grade": false,
     "grade_id": "cell-d17102a8aade0d25",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 1. Data Transformation (10 pts)\n",
    "\n",
    "In a lot of cases, raw data may not come in a form that's amenable to further manipulation or interpretation. Therefore, we may need to transform the raw data so that it better fits our purposes. In this assignment, we will store the data in a more human-friendly tabular format as a `pd.DataFrame`.\n",
    "\n",
    "Complete the function below to return a `pd.DataFrame` of the shape `(569, 31)` with the following columns: \n",
    "```\n",
    "['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "'smoothness error', 'compactness error', 'concavity error',\n",
    "'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "'target']\n",
    "```\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87b04df423cc0e28d15bbe5febbc8074",
     "grade": false,
     "grade_id": "cell-7da0be2f62cc82c6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    cancer_df = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    return cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92ee4d53cd27146a8be39d02f63795ef",
     "grade": true,
     "grade_id": "cell-50152fa70665c294",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_one()\n",
    "\n",
    "assert stu_ans.shape == (569, 31), \"Q1: The shape of your dataframe isn't correct. \"\n",
    "\n",
    "assert list(stu_ans.columns) == ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "       'smoothness error', 'compactness error', 'concavity error',\n",
    "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "       'target'], \"Q1: Please check the column names of your dataframe.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a78261568dfb9f1adeafa68b99ef8585",
     "grade": false,
     "grade_id": "cell-151d159eb6cc7465",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2. Class Distribution (5 pts) \n",
    "\n",
    "It's often a good idea to get some descriptive statistics, such as mean and variance of certain features, on the data at hand to understand the big picture. \n",
    "\n",
    "In particular, it's always a good idea to ask: what is the class distribution? That is, how many instances belong to the *malignant* class (encoded as 0) and the *benign* class (encoded as 1), respectively? Complete the function below to return the class distribution as a `pd.Series` of length 2 whose index is  `['malignant', 'benign']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50ea77f29998202242b8fc589a06d7b6",
     "grade": false,
     "grade_id": "cell-fac24fc5a519ef06",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    dist = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    dist=cancer_df.target.value_counts()\n",
    "    dist.index=[\"benign\", \"malignant\"]\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "620d2ce47498341c76fd5e39c245a34a",
     "grade": true,
     "grade_id": "cell-1ebcc2fe5b95b5df",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_two()\n",
    "\n",
    "assert isinstance(stu_ans, pd.Series), \"Q2: Your result should be a pd.Series.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50408d3338c749f48f8827a5dc46afac",
     "grade": false,
     "grade_id": "cell-33882a911ba5c477",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3. Data Preparation (5 pts)\n",
    "\n",
    "Training a classifier is a *supervised* machine learning problem, in which each instance $x_i$ has a corresponding class label $y_i$. All the instances $x_i$'s are collected into a matrix $X$ (with one instance per row of $X$), and all the corresponding labels are put into a column vector $y$. \n",
    "\n",
    "Now let's prepare the data for use with `scikit-learn`. Complete the function below to split our DataFrame into `X` (the data) and `y` (the labels), and to return them as a `tuple`, where\n",
    "* `X` is a `pd.DataFrame` of the shape `(569, 30)`\n",
    "* `y` is a `pd.Series` of the shape `(569,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1acf373d17f75cdb2a413a8c7165da2",
     "grade": false,
     "grade_id": "cell-61b34fdd39e99b03",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    X, y = None, None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X=cancer_df.drop(\"target\", axis=1)\n",
    "    y=cancer_df[\"target\"]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233b248f916f4429483a55565b3ea3f3",
     "grade": true,
     "grade_id": "cell-0bd5392f7412ea87",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_three()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q3: You should return a tuple!\"\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Q3: X should be a pd.DataFrame. \"\n",
    "assert isinstance(stu_ans[1], pd.Series), \"Q3: y should be a pd.Series. \"\n",
    "assert stu_ans[0].shape == (569, 30), \"Q3: Please check the shape of X.\"\n",
    "assert stu_ans[1].shape == (569,), \"Q3: Please check the shape of y.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "059c086ea299afaea520c438cb634767",
     "grade": false,
     "grade_id": "cell-69dd1eef26cd5aac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 4. Train-test Split (10 pts)\n",
    "\n",
    "For a typical machine learning problem, we'd need two separate datasets, one for training a model and the other for evaluating the trained model for its generalisability to unseen data. `scikit-learn` provides a very handy [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function for this purpose.  \n",
    "\n",
    "Now, complete the function below that uses the `train_test_split` function to split `X` and `y` into training and testing sets. Your function should return a `tuple` `(X_train, X_test, y_train, and y_test)` where\n",
    "\n",
    "\n",
    "* `X_train` is of the shape `(426, 30)`\n",
    "* `X_test` is of the shape `(143, 30)`\n",
    "* `y_train` is of the shape `(426,)`\n",
    "* `y_test` is of the shape `(143,)`\n",
    "\n",
    "**IMPORTANT: Set the random number generator state to the number 42 by specifying `random_state=42` to ensure a deterministic result that matches that of the autograder.**   Why the number 42?  Please see: https://www.theguardian.com/books/2011/feb/03/douglas-adams-42-hitchhiker\n",
    "\n",
    "(In later work, we'll actually use a slightly more sophisticated splitting scheme that uses training, validation, and test sets, but we'll cover this later as part of a technique called cross-validation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07047400cd0a7093d7a1ea683fc3b4a7",
     "grade": false,
     "grade_id": "cell-8e5c85428bc3e008",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_four():\n",
    "    \n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49a1560f285f57d78e10ec222e74a411",
     "grade": true,
     "grade_id": "cell-7c3f4473c01b46df",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_four()\n",
    "\n",
    "assert stu_ans[0].shape == (426, 30), \"Q4: Please check the shape of X_train.\"\n",
    "assert stu_ans[1].shape == (143, 30), \"Q4: Please check the shape of X_test.\"\n",
    "assert stu_ans[2].shape == (426,), \"Q4: Please check the shape of y_train.\"\n",
    "assert stu_ans[3].shape == (143,), \"Q4: Please check the shape of y_test.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ac8dec823c48ef7fc516164b6531c99",
     "grade": false,
     "grade_id": "cell-eef73d2512084cc8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 5. kNN Classifier Construction (5 pts)\n",
    "\n",
    "Use `KNeighborsClassifier` from `scikit-learn` to fit a $k$-Nearest Neighbours ($k$NN) classifier with `X_train` and `y_train` where $k = 1$. Your function should return the trained classifier itself, which is a `sklearn.neighbors.KNeighborsClassifier` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dba13630c35dddfdcc1424b9a74e8c1",
     "grade": false,
     "grade_id": "cell-4b71f9b9bd2e9139",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def answer_five():\n",
    "    knn = None\n",
    "    \n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    knn=KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e9a173daec649e6c9352961cf3909e7",
     "grade": true,
     "grade_id": "cell-746df875c076339d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_five()\n",
    "assert isinstance(stu_ans, KNeighborsClassifier), \"Q5: Please build the required kNN classifier.\"\n",
    "assert len(stu_ans.classes_) == 2, \"Q5: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f626c2c26008ad59fa441c7d2db3fc7",
     "grade": false,
     "grade_id": "cell-2ae5512e5f925fd8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 6. kNN Prediction on Mean Vector (10 pts)\n",
    "\n",
    "It's often useful and interesting to know what class a \"typical\" or \"average\" data point belongs to. Use your kNN classifier from the last question to predict the class label for the *mean vector* of the training data. Your function should return the predicted class label as a singleton numpy array --- either `array([ 0.])` or `array([ 1.])`. \n",
    "\n",
    "If you encounter errors complaining that the shape of your data isn't correct, carefully check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict) of the `predict` function. Another useful hint is to consider what kind of object `X_train` is. How do you make sure it is in the correct shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e84ea41c713038387cb2dd472988182f",
     "grade": false,
     "grade_id": "cell-bbc431b30a17745f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    pred = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    knn=KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    mean_vector=cancer_df.drop(\"target\", axis=1).mean()\n",
    "    pred=knn.predict(np.array(mean_vector).reshape(1,mean_vector.shape[0]))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "494638ad6ea8a1ed997da2a1028c34d1",
     "grade": true,
     "grade_id": "cell-c93e4911f581b5cb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_six()\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q6: Your function should return a np.ndarray. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acebbf177184da50e3d30ea12c5b5f97",
     "grade": false,
     "grade_id": "cell-cba29490ecc74222",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 7. kNN Prediction on the Test Set (5 pts)\n",
    "\n",
    "Now, use your kNN classifier to predict class labels for the test set `X_test`. Your function should return a binary `np.ndarray` of the shape `(143,)` whose values are either `0.0` or `1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac1828dd71189cd5cbfa7f7fa4713b9a",
     "grade": false,
     "grade_id": "cell-556e3b89a523853a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    preds = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    knn=KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    preds=knn.predict(X_test)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1eb28af45e0c38e4506e3b11fa04622f",
     "grade": true,
     "grade_id": "cell-1fc7ffa2d7e05814",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_seven()\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q7: Your function should return a np.ndarray. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01c3548a6770290943242e4572fa04fa",
     "grade": false,
     "grade_id": "cell-9b690a899cf1faea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 8. Evaluation on the Test Set (5 pts) \n",
    "\n",
    "Once you have the predictions on the test set, you may compare them with the ground-truth labels to gauge how well your model performs when given unseen data. \n",
    "\n",
    "Complete the function below to compute the score (mean accuracy) of your kNN classifier using the test set `X_test` and the test labels `y_test`. The function should return a `float` between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "116e205832d7734f41a6c6d07a90d1c7",
     "grade": false,
     "grade_id": "cell-dc56668e96e99a63",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    score = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    knn=KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    score=knn.score(X_test, y_test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43e6c71469a655accc05570c3f17ac5a",
     "grade": true,
     "grade_id": "cell-edfa0ff11db4a6d9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eight()\n",
    "\n",
    "assert isinstance(stu_ans, float), \"Q8: Your function should return a float. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78c6a2f4fee484176f75455a6c91cab7",
     "grade": false,
     "grade_id": "cell-2f4bb718715b7db8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Optional plot\n",
    "\n",
    "Note: The following plots will help you to evaluate the model with showing the prediction accuracy in training and testing set.\n",
    "\n",
    "Try using the plotting function below to visualize the different predicition scores between training and test sets, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2052bee013604481351deb7fc392c409",
     "grade": false,
     "grade_id": "cell-3a29268b05bec923",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_plot(knn):\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     %matplotlib notebook\n",
    "\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train==0]\n",
    "    mal_train_y = y_train[y_train==0]\n",
    "    ben_train_X = X_train[y_train==1]\n",
    "    ben_train_y = y_train[y_train==1]\n",
    "\n",
    "    mal_test_X = X_test[y_test==0]\n",
    "    mal_test_y = y_test[y_test==0]\n",
    "    ben_test_X = X_test[y_test==1]\n",
    "    ben_test_y = y_test[y_test==1]\n",
    "\n",
    "    scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y), \n",
    "              knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the scores as a bar chart\n",
    "    bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])\n",
    "\n",
    "    # directly label the score onto the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2), \n",
    "                     ha='center', color='w', fontsize=11)\n",
    "\n",
    "    # remove all the ticks (both axes), and tick labels on the Y axis\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    # remove the frame of the chart\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.xticks([0,1,2,3], ['Malignant\\nTraining', 'Benign\\nTraining', 'Malignant\\nTest', 'Benign\\nTest'], alpha=0.8);\n",
    "    plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b86e43682bde0d595e9f71b770205319",
     "grade": false,
     "grade_id": "cell-200de5f487ac9fa1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Uncomment the below line to see the visualization. You can pass in any trained classifier as an argument.\n",
    "\n",
    "**Comment out** the the below line when submitting your notebook for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to comment it out when submitting the notebook\n",
    "# accuracy_plot(answer_five())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "807700a4417faf916e02ea785683f07f",
     "grade": false,
     "grade_id": "cell-7d573c035102d74b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 9. Hyper-parameter Tuning (5 pts)\n",
    "\n",
    "It's common to experiment with different configurations of a model, also known as \"hyper-parameters\" which are typically specified in advance of starting the step of estimating the learnable \"parameters\" of a specific model configuration in order to achieve better performance. The main crucial hyper-parameter of a k-NN model is the number $k$, the number of neighbors to examine. \n",
    "\n",
    "Change $k$ to 15 and fit the model with training data. Complete the function below to return the trained model, which is a `sklearn.neighbors.KNeighborsClassifier` object. Compare this with the results above for $k$ = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd368f7ef582de2c6a34cd4696d5ecf3",
     "grade": false,
     "grade_id": "cell-3bc80326a3e99e05",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def answer_nine():\n",
    "    knn = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    knn=KNeighborsClassifier(n_neighbors=15)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e76b8ab979b61e4bfbb7268debe021b8",
     "grade": true,
     "grade_id": "cell-e724a46e381ed1b7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_nine()\n",
    "assert isinstance(stu_ans, KNeighborsClassifier), \"Q9: Please build the required kNN classifier.\"\n",
    "assert len(stu_ans.classes_) == 2, \"Q9: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to comment it out when submitting the notebook\n",
    "# accuracy_plot(answer_nine())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0905268f819993696d61ad9f9e1738d2",
     "grade": false,
     "grade_id": "cell-67fb7570879a6ed9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 10. Weighted k-NN (5 pts)\n",
    "\n",
    "Keeping $k = 15$, now change the k-NN method to use a *weighted* distance measure: this means closer neighbors of a query point will have more influence on the prediction than neighbors which are a greater distance away. (Normally, the default k-NN classifier uses a uniform weighting, i.e. it ignores how far a neighbor is and just sees that it exists.)\n",
    "\n",
    "Your function below should return a trained kNN classifier of the type `sklearn.neighbors.KNeighborsClassifier`. (You may find it helpful to plot and compare the results with the unweighted distance measure, using the provided plotting function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ae6049618c4a782be507ccd01ee8813",
     "grade": false,
     "grade_id": "cell-4243c4d7cfa2960e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_ten():\n",
    "    knn = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    knn=KNeighborsClassifier(n_neighbors=15, weights=\"distance\")\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95fb2f9eee2699563a0abaad5db8dee2",
     "grade": true,
     "grade_id": "cell-558b71c1a69189f5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_ten()\n",
    "assert isinstance(stu_ans, KNeighborsClassifier), \"Q9: Please build the required kNN classifier.\"\n",
    "assert len(stu_ans.classes_) == 2, \"Q9: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to comment it out when submitting the notebook\n",
    "# accuracy_plot(answer_ten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40c306fde694591056a5b00cb143a058",
     "grade": false,
     "grade_id": "cell-991ef995f3f147aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 11: Model parameter tuning (15 points)\n",
    "\n",
    "It is important to improve algorithm design through automatically changing the parameter based on data-driven evidence, because it is more effective than just 'trying out' different parameters by hand.\n",
    "\n",
    "Perform a simple parameter sweep for all **odd** values of $k$ from 1 to 19 inclusive, and return the optimal value of $k$ that leads to the highest overall *test set accuracy* on this train/test split.  Accuracy is computed using the **score** method. Your code should return an integer between 1 and 19. In case of a tie, return the smallest best $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96d2c36c4d1078ea90306d3af7448c85",
     "grade": false,
     "grade_id": "cell-feeb5e4810d6c9e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_eleven():\n",
    "    k_best = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "    \n",
    "    k_range=list(range(1,20,2))\n",
    "    scores=[]\n",
    "    for k in k_range:\n",
    "        knn=KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test))\n",
    "    \n",
    "    k_dict=dict(zip(k_range, scores))\n",
    "    max_val=max(k_dict.values())\n",
    "    k_best=[key for key, value in k_dict.items() if value==max_val]\n",
    "    k_best=k_best[0]\n",
    "    \n",
    "    return k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23fa51cf747fbd00ac1d5bc2253c707d",
     "grade": true,
     "grade_id": "cell-e17d6199583d1080",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eleven()\n",
    "\n",
    "assert isinstance(stu_ans, int), \"Q11: Your function should return an integer. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: Overfitting  (15 points)\n",
    "\n",
    "A key sign of overfitting is obtaining a training set accuracy that is extremely high (or even perfect), but a test set accuracy that is considerably lower. It is tempting to use a classifier that does so well on the training data it was given, but reality sets in when we try to use this overfit classifier on new test data and we discover it does not in fact generalize well.\n",
    "\n",
    "Using the same set of possible k-NN classifiers and values of $k$ as the previous question (Q11), look for a scenario where overfitting is likely to be happening, by finding the optimal value for $k$ if your goal was to pick the classifier that did best only on the **training set**.  Compute what the resulting test set accuracy would have been, if you had picked that training-set-based value for $k$.\n",
    "\n",
    "Your function should return an (`int`, `float`, `float`) tuple, as follows:\n",
    "\n",
    "`tuple[0]`: the optimal value of $k$ that maximizes *training set* accuracy\n",
    "\n",
    "`tuple[1]`: the corresponding *training set* accuracy for that optimal $k$\n",
    "\n",
    "`tuple[2]`: the corresponding *test set* accuracy that you would have received *if* you had used that optimal $k$.\n",
    "\n",
    "(It is instructive to compare this test set accuracy with the best one you were able to achieve in question 11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0710d66e6fc7580cab9f50af49180904",
     "grade": false,
     "grade_id": "cell-fa4b5a5c9ec7dd40",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_twelve():\n",
    "    k_best = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    cancer_df=pd.DataFrame(cancer[\"data\"])\n",
    "    cancer_df.columns=cancer[\"feature_names\"]\n",
    "    cancer_df[\"target\"]=cancer[\"target\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(\"target\", axis=1), cancer_df[\"target\"], random_state=42)\n",
    "\n",
    "    k_range=list(range(1,20,2))\n",
    "    scores_train=[]\n",
    "    for k in k_range:\n",
    "        knn=KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores_train.append(knn.score(X_train, y_train))\n",
    "\n",
    "    k_dict_train=dict(zip(k_range, scores_train))\n",
    "    max_val=max(k_dict_train.values())\n",
    "    k_best_train=[key for key, value in k_dict_train.items() if value==max_val]\n",
    "    k_best_train=k_best_train[0]\n",
    "    \n",
    "    scores_test=[]\n",
    "    for k in k_range:\n",
    "        knn=KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores_test.append(knn.score(X_test, y_test))\n",
    "\n",
    "    k_dict_test=dict(zip(k_range, scores_test))\n",
    "    k_best=(k_best_train, k_dict_train[k_best_train], k_dict_test[k_best_train])\n",
    "    \n",
    "    return k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81073a47b9cf1997a55d102f6f2c072f",
     "grade": true,
     "grade_id": "cell-9d8ba54a5e282cd7",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_twelve()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q12: Your function should return a tuple. \"\n",
    "assert len(stu_ans) == 3, \"Q12: The length of your returned tuple should be 3. \"\n",
    "assert isinstance(stu_ans[0], int), \"Q12: Your tuple format should be (*int*, float, float). \"\n",
    "assert isinstance(stu_ans[1], float), \"Q12: Your tuple format should be (int, *float*, float). \"\n",
    "assert isinstance(stu_ans[1], float), \"Q12: Your tuple format should be (int, float, *float*). \"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v2_assignment1_part2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
