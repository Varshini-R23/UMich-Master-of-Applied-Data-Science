{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f79a043a06dada39f406fa40c3301e60",
     "grade": false,
     "grade_id": "cell-018440ed2f1b6a62",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 3\n",
    "The data you will be using is the FOIA data gathered from the city of Ann Arbor on parking tickets. The repository is made up of a set of Excel files which you're going to have to figure out how to load into a pandas `DataFrame` (time to check the APIs!). The files may have more than one sheet in them (who knows why!?). I'd like you to answer the following questions for me.\n",
    "\n",
    "This is a substantial amount of data. Therefore, things will take a while to run. For testing purposes, I would recommend using a reasonable representative subset before applying your functions on the entire dataframe. Make sure you remove any extraneous outputs before you turn in your final copy though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98694c9269352e7d8679956841660959",
     "grade": false,
     "grade_id": "cell-7e5190c7ff1f2e42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "## Question 1: load_ticket_data()\n",
    "First, write the code to create a single `DataFrame` object in a function called `load_ticket_data()`. This function should return the full dataframe and take no parameters (you can assume the ticket files are in the same directory as your assignment notebook). Column labels should be as follows:\n",
    "\n",
    "`['Ticket #', 'Badge', 'Issue Date ', 'IssueTime', 'Plate', 'State',\n",
    "       'Make', 'Model', 'Violation', ' Description', 'Location', 'Meter',\n",
    "       ' Fine ', 'Penalty']`\n",
    "\n",
    "\n",
    "Here are some hints.\n",
    "<ol>\n",
    "<li> Be sure to scroll through every single sheet to make sure what rows should be dropped.</li>\n",
    "<li> Make sure to exclude unnecessary footers and headers from the datafile.</li>\n",
    "<li> Check if your header labels are correct.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6d4a0b9b6d884189c3b2fbd4dee3441a",
     "grade": false,
     "grade_id": "cell-85d6b39df17aa02f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_ticket_data():\n",
    "    import xlrd\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    # Filter all warnings. If you would like to see the warnings, please comment the two lines below.\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # load all the Excel files in order to count the number of sheets in them\n",
    "    file1 = xlrd.open_workbook('AnnArbor-TicketViolation2015.xls', on_demand=True)\n",
    "    file2 = xlrd.open_workbook('AnnArbor-TicketViolation2016.xls', on_demand=True)\n",
    "    file3 = xlrd.open_workbook('AnnArbor-TicketViolation2017.xls', on_demand=True)\n",
    "    file4 = xlrd.open_workbook('AnnArbor-TicketViolation2018.xls', on_demand=True)\n",
    "    file5 = xlrd.open_workbook('AnnArbor-TicketViolation2019.xls', on_demand=True)\n",
    "    file6 = xlrd.open_workbook('AnnArbor-TicketViolation-jan2020.xls', on_demand=True)\n",
    "\n",
    "    # create a list of Excel files\n",
    "    files=[file1, file2, file3, file4, file5, file6]\n",
    "\n",
    "    # create an empty dictionary to store resulting dataframes, and a file count accumulator for dictionary keys\n",
    "    df_dict={}\n",
    "    file_num=0\n",
    "\n",
    "    # loop through the Excel files\n",
    "    for i in files:\n",
    "        file_num+=1\n",
    "\n",
    "        # loop through the sheets in the Excel files\n",
    "        for j in range(len(i.sheet_names())):\n",
    "\n",
    "            # make the second row the header if we're looking at the first sheet of all Excel files except the last one\n",
    "            if j==0 and file_num!=6:\n",
    "                df=pd.read_excel(i, sheet_name=j, header=1)\n",
    "\n",
    "            # make the second row the header and skip the last row if we're looking at the first sheet of the last Excel file\n",
    "            elif j==0 and file_num==6:\n",
    "                df=pd.read_excel(i, sheet_name=j, header=1, skipfooter=1)\n",
    "\n",
    "            # skip the last row if we're looking at the last sheet of all Excel files and add a header\n",
    "            elif j==(len(i.sheet_names())-1):\n",
    "                df=pd.read_excel(i, sheet_name=j, header=None,\n",
    "                                 names=['Ticket #','Badge','Issue Date ','IssueTime','Plate','State','Make','Model','Violation',' Description',\n",
    "                                        'Location','Meter',' Fine ','Penalty'], skipfooter=1)\n",
    "\n",
    "            # add a header for all other sheets of all Excel files\n",
    "            else:\n",
    "                df=pd.read_excel(i, sheet_name=j, header=None,\n",
    "                                 names=['Ticket #','Badge','Issue Date ','IssueTime','Plate','State','Make','Model','Violation',' Description',\n",
    "                                        'Location','Meter',' Fine ','Penalty'])\n",
    "\n",
    "            # drop rows containing NaN values in the Badge column (these rows are blank for other columns too)\n",
    "            df.dropna(subset=[\"Badge\"], axis=0, inplace=True)\n",
    "\n",
    "            # append the dataframe to the dictionary, resulting in a dictionary of dataframes\n",
    "            df_dict[str(file_num)+\"-\"+str(j)]=df\n",
    "\n",
    "    # create an empty dataframe\n",
    "    full_df=pd.DataFrame()\n",
    "\n",
    "    # loop through all the keys in the dictionary of dataframes\n",
    "    for k in df_dict.keys():\n",
    "\n",
    "        # concatenate all the dataframes within the dictionary to form one big dataframe\n",
    "        full_df=pd.concat([full_df, df_dict[k]])\n",
    "\n",
    "    return full_df\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "29ea532dada4e7b1eb210da385b8c3e4",
     "grade": true,
     "grade_id": "cell-ece042ccd621104a",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df_1_test = load_ticket_data()\n",
    "assert isinstance(df_1_test, pd.DataFrame), \"Q1: What your function returns must be pd.DataFrame.\"\n",
    "assert len(df_1_test) == 811439, \"Q1: There should be 811439 rows in the dataframe.\"\n",
    "assert len(df_1_test.columns) == 14, \"Q1: There should be 14 columns in the dataframe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b796a0f6835cc7a9a16ff211790053db",
     "grade": false,
     "grade_id": "cell-babe0ff2a1fc6b17",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2: generate_descriptors()\n",
    "Write a function called `generate_descriptors(df)` which takes in the DataFrame you loaded from Question1 and returns a dataframe of all unique ticket descriptions and how frequent they are (e.g. it will tell you how many \"HANDICAP\" or \"NO PERMITS U/M\" tickets have been issued) for each of the following three time periods: morning (3 am to 11:59 am), afternoon (12 pm - 5:59 pm), and evening (6 pm - 2:59 am).\n",
    "\n",
    "* Make sure you drop na values of input `df`. \n",
    "* The DataFrame which `generate_descriptors(df)` returns should have 3 rows and 51 columns. \n",
    "* Index should be labelled as `Morning`, `Afternoon`, and `Evening`. \n",
    "* Column names should be unique values of `df[\"Description\"]`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae2402240ea1b46bcd76c7b694854c94",
     "grade": false,
     "grade_id": "cell-b0c3202c000aada4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_descriptors(df):\n",
    "    import xlrd\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    # Filter all warnings. If you would like to see the warnings, please comment the two lines below.\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # drop rows with NaN values in Description column\n",
    "    df.dropna(subset=[\" Description\"], axis=0, inplace=True)\n",
    "\n",
    "    # define a function to get time period based on time in IssueTime column\n",
    "    def time_period(time):\n",
    "    \n",
    "        if time>=300 and time<=1159:\n",
    "            return \"Morning\"\n",
    "        elif time>=1200 and time<=1759:\n",
    "            return \"Afternoon\"\n",
    "        else:\n",
    "            return \"Evening\"\n",
    "    \n",
    "    # create a new column TimePeriod specifying the time period based on the IssueTime column\n",
    "    df[\"TimePeriod\"]=df.apply(lambda x: time_period(x[\"IssueTime\"]), axis=1)\n",
    "    \n",
    "#     # convert IssueTime column data type to string\n",
    "#     df[\"IssueTime\"]=df[\"IssueTime\"].astype(\"str\")\n",
    "    \n",
    "#     # remove decimal point and zeros from the time string\n",
    "#     df[\"IssueTime\"]=df[\"IssueTime\"].str.replace(\".0\", \"\")\n",
    "    \n",
    "#     # ensure that time string has 4 digits by adding leading zeros where necessary\n",
    "#     df['IssueTime']=df['IssueTime'].apply(lambda x: x.zfill(4))\n",
    "    \n",
    "#     # convert time string to datetime data type and format\n",
    "#     df[\"IssueTime\"]=pd.to_datetime(df[\"IssueTime\"], format=\"%H%M\")\n",
    "    \n",
    "#     # reset index to get unique indices\n",
    "#     df.reset_index(inplace=True)\n",
    "\n",
    "#     # create a new column with details of time periods based on the hour in IssueTime column\n",
    "#     df[\"TimePeriod\"]=pd.cut(df[\"IssueTime\"].dt.hour, bins=[0, 3, 12, 18, 24], labels=[\"Evening\", \"Morning\", \"Afternoon\", \"Evening\"], right=False, include_lowest=True, ordered=False)\n",
    "    \n",
    "    # strip extra white spaces from column names\n",
    "    cols=list(df.columns)\n",
    "    cols=[x.strip() for x in cols]\n",
    "    df.columns=cols\n",
    "    \n",
    "    # group by TimePeriod and Description, aggregate with count of Description\n",
    "    df_q2=df.groupby([\"TimePeriod\", \"Description\"])[\"Description\"].count().unstack()\n",
    "    \n",
    "#     raise NotImplementedError()\n",
    "    return df_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "193f197dec728ed4e5b59e7e7f54dbec",
     "grade": true,
     "grade_id": "cell-c97ee66ccdccb430",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_q2 = generate_descriptors(load_ticket_data())\n",
    "assert df_q2.shape == (3, 51), \"Q2: The shape of the DataFrame is incorrect.\"\n",
    "assert \"Morning\" in df_q2.index, 'Q2: \"Morning\" shoud be in the index of the DataFrame'\n",
    "assert \"Afternoon\" in df_q2.index, 'Q2: \"Afternoon\" should be in the index of the DataFrame'\n",
    "assert \"Evening\" in df_q2.index, 'Q2: \"Evening\" should be in the index of the DataFrame'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0a21b223301cd89aefc8a763a46f7d05",
     "grade": false,
     "grade_id": "cell-89d80693491a3d33",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3: common_car_make()\n",
    "What is the most common make of car which received tickets from the state of NY? The answer should be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6b99b41fbc6e7ba6bc5136a23f88a5e8",
     "grade": false,
     "grade_id": "cell-bce4d6f2ecdd1297",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def common_car_make():\n",
    "    import xlrd\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    # Filter all warnings. If you would like to see the warnings, please comment the two lines below.\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    df = load_ticket_data()\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # grouping by state and make of car, and then selecting the top-most sorted value for the state of NY gives the necessary answer\n",
    "    return df.groupby([\"State\", \"Make\"])[\"Make\"].count().unstack().loc['NY'].sort_values(ascending=False).index[0]\n",
    "    \n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "329494751336ddd909063ed0b5f0b732",
     "grade": true,
     "grade_id": "cell-780b5a4da845dbc3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "answer3 = common_car_make()\n",
    "assert isinstance(answer3, str), \"Q3: Your answer should be a string type.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73f8548716e27590d2e2801d5c452606",
     "grade": false,
     "grade_id": "cell-2e54816014e48c18",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "## Question 4: fine_per_plates()\n",
    "Starting in 2004 Michigan moved to issuing plates with the format of ABC1234. That got me thinking, how many vanity plate holders there are in our dataset? Count for me the number of Michigan vehicles with plates in the following formats that have received a ticket:\n",
    "- ABC1234\n",
    "- ABC123\n",
    "- 123ABC\n",
    "- Vanity Plates (i.e. anything other than the aforementioned formats)\n",
    "\n",
    "Complete the function `fine_per_plates()` returning a dictionary. The dictinary should be formatted as follows:\n",
    "```\n",
    "plates_dict = {\"ABC1234\":the_number_of_vehicles,\n",
    "                \"ABC123\":the_number_of_vehicles,\n",
    "                \"123ABC\":the_number_of_vehicles,\n",
    "                \"vanity\":the_number_of_vehicles}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e91f2ea1a824e036d1fddc561b4f26d3",
     "grade": false,
     "grade_id": "cell-8c3d74335c0d489a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fine_per_plates():\n",
    "    import xlrd\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    # Filter all warnings. If you would like to see the warnings, please comment the two lines below.\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    df = load_ticket_data()\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # define a function to match license plate formats and return them\n",
    "    def plate_format(s):\n",
    "    \n",
    "        if len(re.findall(\"^[a-zA-Z]{3}\\d{4}$\", s))!=0:\n",
    "            return \"ABC1234\"\n",
    "        elif len(re.findall(\"^[a-zA-Z]{3}\\d{3}$\", s))!=0:\n",
    "            return \"ABC123\"\n",
    "        elif len(re.findall(\"^\\d{3}[a-zA-Z]{3}$\", s))!=0:\n",
    "            return \"123ABC\"\n",
    "        else:\n",
    "            return \"vanity\"\n",
    "    \n",
    "    # create a new column PlateFormat specifying the license plate format based on the Plate column\n",
    "    df[\"PlateFormat\"]=df.apply(lambda x: plate_format(str(x[\"Plate\"])), axis=1)\n",
    "    \n",
    "    # return a dictionary of count of each license plate format for the state of MI\n",
    "    plates_dict=dict(df.loc[df.State==\"MI\"].PlateFormat.value_counts())\n",
    "    \n",
    "    return plates_dict\n",
    "    \n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e0103e9d106caf0e70656b956ead7fa5",
     "grade": true,
     "grade_id": "cell-aaaa11ef7d26f4cf",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(fine_per_plates())==4, \"Return a dictionary with four items.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "mads_data_manipulation_v1_assignment3"
   ]
  },
  "etc_identifier": "7ca0093b-b622-4463-9696-65f1e0f33522",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
