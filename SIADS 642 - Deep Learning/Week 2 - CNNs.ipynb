{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a65256d7eef6e7d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homework 2: Convolutional Neural Networks (100 points)\n",
    "\n",
    "### Overview\n",
    "\n",
    "With new knowledge of convolutional neural networks, we can accomplish a more difficult image recognition task. The CIFAR-10 classification dataset consists of 60,000 labelled images split between 10 classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships and trucks.\n",
    "\n",
    "For the purposes of this assignment, we will compare two models on the same dataset: a fully connected neural network (as in Homework 1) called ANN and a new convolutional architecture called CNN, as outlined in the next section. To be fair, we attempt to allow the same number of trainable parameters in the ANN as the CNN, which means we need to use the same input transformation to flatten grayscale used in Homework 1 for the ANN. The CNN reaps the full benefit of the original 2D image in RGB.\n",
    "\n",
    "### CNN Architecture\n",
    "\n",
    "Each image consists of 32x32 RGB pixel values between 0 and 255. We do not need to perform any preprocessing as the convolutional model will use all three channels concurrently as input.\n",
    "\n",
    "The architecture in use has 5 layers: a convolution layer followed by a pooling layer, then another convolutional layer, then two fully connected dense layers. The latter of these has 10 neurons to provide classification output.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "At the bottom of this notebook file, there are four short answer questions testing your understanding of this neural network architecture. As before, some questions will require you to experiment with model hyperparameters.\n",
    "\n",
    "Below each question is a cell with the text “Type Markdown and LaTex.” Double-click the cell and type your response to the question. Save your responses by clicking on the floppy disk icon or choosing File - Save and Checkpoint.\n",
    "\n",
    "After responding to the questions, download your notebook as a `.html` file by choosing File - Download as - html (.html). You will be submitting this `.html` file to your instructor for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTransform = transforms.Compose([transforms.RandomRotation(5),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])\n",
    "testTransform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'assets_week2'\n",
    "trainDataset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=trainTransform)\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testDataset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True, transform=testTransform)\n",
    "testLoader = torch.utils.data.DataLoader(testDataset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        # Note that 'layer' and 'dense' differ only in name (to show similarity to CNN)\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.layer1 = nn.Linear(1024, 100)\n",
    "        self.layer2 = nn.Linear(100, 15 * 5 * 5)\n",
    "        self.dense1 = nn.Linear(15 * 5 * 5, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activate(self.layer1(x))\n",
    "        x = self.activate(self.layer2(x))\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(3, 24, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(24, outChannels, 5)\n",
    "        self.dense1 = nn.Linear(outChannels * 5 * 5, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        x = x.view(-1, self.outChannels * 5 * 5)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 100\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.001\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Beginning training!\n",
      "Epoch [1/10], Step [2000/12500], ANN Loss: 2.0651431404650213, CNN Loss: 2.013633511543274\n",
      "Epoch [1/10], Step [4000/12500], ANN Loss: 1.9222866840958595, CNN Loss: 1.6558185454905032\n",
      "Epoch [1/10], Step [6000/12500], ANN Loss: 1.866415710836649, CNN Loss: 1.5057528860867024\n",
      "Epoch [1/10], Step [8000/12500], ANN Loss: 1.8486922891438007, CNN Loss: 1.4342953490763903\n",
      "Epoch [1/10], Step [10000/12500], ANN Loss: 1.819504773169756, CNN Loss: 1.3722973599135875\n",
      "Epoch [1/10], Step [12000/12500], ANN Loss: 1.792697628468275, CNN Loss: 1.2984128977954388\n",
      "Epoch [2/10], Step [2000/12500], ANN Loss: 1.7398476891368628, CNN Loss: 1.2341302007064223\n",
      "Epoch [2/10], Step [4000/12500], ANN Loss: 1.721903137549758, CNN Loss: 1.2104474659375846\n",
      "Epoch [2/10], Step [6000/12500], ANN Loss: 1.7148346040248872, CNN Loss: 1.1882972740493716\n",
      "Epoch [2/10], Step [8000/12500], ANN Loss: 1.7160489804148673, CNN Loss: 1.145599445145577\n",
      "Epoch [2/10], Step [10000/12500], ANN Loss: 1.7132752705663443, CNN Loss: 1.1383376959050073\n",
      "Epoch [2/10], Step [12000/12500], ANN Loss: 1.7002093015909194, CNN Loss: 1.1098406704533845\n",
      "Epoch [3/10], Step [2000/12500], ANN Loss: 1.6477987474501132, CNN Loss: 1.0365290348343552\n",
      "Epoch [3/10], Step [4000/12500], ANN Loss: 1.6337226323038339, CNN Loss: 1.0494026930052787\n",
      "Epoch [3/10], Step [6000/12500], ANN Loss: 1.6474793972000479, CNN Loss: 1.0523895462220534\n",
      "Epoch [3/10], Step [8000/12500], ANN Loss: 1.6477712057083844, CNN Loss: 1.011653719461523\n",
      "Epoch [3/10], Step [10000/12500], ANN Loss: 1.6051863313913346, CNN Loss: 1.00052612516284\n",
      "Epoch [3/10], Step [12000/12500], ANN Loss: 1.6276315301209687, CNN Loss: 1.0187321721184999\n",
      "Epoch [4/10], Step [2000/12500], ANN Loss: 1.5762041495591401, CNN Loss: 0.9426752589156385\n",
      "Epoch [4/10], Step [4000/12500], ANN Loss: 1.5712711747586727, CNN Loss: 0.9474933603610843\n",
      "Epoch [4/10], Step [6000/12500], ANN Loss: 1.5976572595238685, CNN Loss: 0.9470418953204062\n",
      "Epoch [4/10], Step [8000/12500], ANN Loss: 1.5901475484520198, CNN Loss: 0.932390942457132\n",
      "Epoch [4/10], Step [10000/12500], ANN Loss: 1.5551417142748833, CNN Loss: 0.9489011690164916\n",
      "Epoch [4/10], Step [12000/12500], ANN Loss: 1.5827486747652293, CNN Loss: 0.9343826218161266\n",
      "Epoch [5/10], Step [2000/12500], ANN Loss: 1.5165686519816517, CNN Loss: 0.8472224854659289\n",
      "Epoch [5/10], Step [4000/12500], ANN Loss: 1.5485205021798611, CNN Loss: 0.8893369567301125\n",
      "Epoch [5/10], Step [6000/12500], ANN Loss: 1.5205376298725606, CNN Loss: 0.8807715172644239\n",
      "Epoch [5/10], Step [8000/12500], ANN Loss: 1.5323724678643047, CNN Loss: 0.8913451969886664\n",
      "Epoch [5/10], Step [10000/12500], ANN Loss: 1.5314961768835782, CNN Loss: 0.8796990527752787\n",
      "Epoch [5/10], Step [12000/12500], ANN Loss: 1.536129963710904, CNN Loss: 0.8806483223619871\n",
      "Epoch [6/10], Step [2000/12500], ANN Loss: 1.4802862400189043, CNN Loss: 0.8298659963163082\n",
      "Epoch [6/10], Step [4000/12500], ANN Loss: 1.476063256882131, CNN Loss: 0.8027602099557407\n",
      "Epoch [6/10], Step [6000/12500], ANN Loss: 1.4967780131846666, CNN Loss: 0.8355807928424328\n",
      "Epoch [6/10], Step [8000/12500], ANN Loss: 1.5043121395856143, CNN Loss: 0.8413949163048529\n",
      "Epoch [6/10], Step [10000/12500], ANN Loss: 1.4949796938300133, CNN Loss: 0.8353093208731152\n",
      "Epoch [6/10], Step [12000/12500], ANN Loss: 1.4943062402904033, CNN Loss: 0.8416607727247756\n",
      "Epoch [7/10], Step [2000/12500], ANN Loss: 1.4377242470234632, CNN Loss: 0.7606895243790932\n",
      "Epoch [7/10], Step [4000/12500], ANN Loss: 1.4312388415560127, CNN Loss: 0.7757162613394903\n",
      "Epoch [7/10], Step [6000/12500], ANN Loss: 1.4408025848194956, CNN Loss: 0.7672899594241753\n",
      "Epoch [7/10], Step [8000/12500], ANN Loss: 1.4820247048214077, CNN Loss: 0.8149094306563492\n",
      "Epoch [7/10], Step [10000/12500], ANN Loss: 1.4745022121742368, CNN Loss: 0.8064180900144856\n",
      "Epoch [7/10], Step [12000/12500], ANN Loss: 1.476308487988077, CNN Loss: 0.8143487987401895\n",
      "Epoch [8/10], Step [2000/12500], ANN Loss: 1.3793731155879796, CNN Loss: 0.6983925977785257\n",
      "Epoch [8/10], Step [4000/12500], ANN Loss: 1.4132366844788193, CNN Loss: 0.7383941475944011\n",
      "Epoch [8/10], Step [6000/12500], ANN Loss: 1.4262815335281194, CNN Loss: 0.7728403222198831\n",
      "Epoch [8/10], Step [8000/12500], ANN Loss: 1.443523860409856, CNN Loss: 0.7556137846032798\n",
      "Epoch [8/10], Step [10000/12500], ANN Loss: 1.4404414008408786, CNN Loss: 0.7582781179114245\n",
      "Epoch [8/10], Step [12000/12500], ANN Loss: 1.445216628395021, CNN Loss: 0.7722727894082781\n",
      "Epoch [9/10], Step [2000/12500], ANN Loss: 1.3494324534758926, CNN Loss: 0.68467158749589\n",
      "Epoch [9/10], Step [4000/12500], ANN Loss: 1.381182004891336, CNN Loss: 0.7074329970598628\n",
      "Epoch [9/10], Step [6000/12500], ANN Loss: 1.4121976839527488, CNN Loss: 0.7206262572810519\n",
      "Epoch [9/10], Step [8000/12500], ANN Loss: 1.4008915499709547, CNN Loss: 0.743101120182313\n",
      "Epoch [9/10], Step [10000/12500], ANN Loss: 1.4091352163776756, CNN Loss: 0.728326395823271\n",
      "Epoch [9/10], Step [12000/12500], ANN Loss: 1.4186538611128927, CNN Loss: 0.7592411840429996\n",
      "Epoch [10/10], Step [2000/12500], ANN Loss: 1.348081712121144, CNN Loss: 0.6534109677248489\n",
      "Epoch [10/10], Step [4000/12500], ANN Loss: 1.336207102663815, CNN Loss: 0.6879686666456837\n",
      "Epoch [10/10], Step [6000/12500], ANN Loss: 1.3368962955512107, CNN Loss: 0.6801909110939596\n",
      "Epoch [10/10], Step [8000/12500], ANN Loss: 1.4035576878599823, CNN Loss: 0.7222781460684491\n",
      "Epoch [10/10], Step [10000/12500], ANN Loss: 1.3830730506032705, CNN Loss: 0.7268062270561931\n",
      "Epoch [10/10], Step [12000/12500], ANN Loss: 1.3811912578102201, CNN Loss: 0.7196769998593955\n",
      "\n",
      ">>> Beginning validation!\n",
      "ANN validation accuracy: 41.68%, CNN validation accuracy: 68.23%\n"
     ]
    }
   ],
   "source": [
    "ann = ANNModel(hiddenSize, dropoutRate, activation)\n",
    "cnn = CNNModel(hiddenSize, numFilters, dropoutRate, activation)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(list(ann.parameters()) + list(cnn.parameters()), lr=learningRate, momentum=momentum)\n",
    "\n",
    "print('>>> Beginning training!') \n",
    "ann.train()\n",
    "cnn.train()\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "    annRunningLoss, cnnRunningLoss = 0, 0\n",
    "    for i, (inputs, labels) in enumerate(trainLoader, 0):\n",
    "        annInputs = torch.sum(inputs, axis=1).view(-1, 32*32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        annOutputs = ann(annInputs)\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        \n",
    "        # Backpropagation\n",
    "        annLoss = criterion(annOutputs, labels)\n",
    "        cnnLoss = criterion(cnnOutputs, labels)\n",
    "        annLoss.backward()\n",
    "        cnnLoss.backward()\n",
    "        \n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "\n",
    "        annRunningLoss += annLoss.item()\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        if (i+1) % 2000 == 0:    # print every 2000 mini-batches\n",
    "            print('Epoch [{}/{}], Step [{}/{}], ANN Loss: {}, CNN Loss: {}'.format(epoch + 1, numEpochs, i + 1, len(trainDataset)//4, annRunningLoss/2000, cnnRunningLoss/2000))\n",
    "            annRunningLoss, cnnRunningLoss = 0, 0\n",
    "\n",
    "print()\n",
    "print('>>> Beginning validation!')\n",
    "ann.eval()\n",
    "cnn.eval()\n",
    "annCorrect, cnnCorrect = 0, 0\n",
    "total = 0\n",
    "for inputs, labels in testLoader:\n",
    "    annInputs = torch.sum(inputs, axis=1).view(-1, 32*32)\n",
    "    annOutputs = ann(annInputs)\n",
    "    cnnOutputs = cnn(inputs)\n",
    "    _, annPredicted = torch.max(annOutputs.data, 1)\n",
    "    _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    annCorrect += (annPredicted == labels).sum().item()\n",
    "    cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "print('ANN validation accuracy: {}%, CNN validation accuracy: {}%'.format(annCorrect / total * 100, cnnCorrect / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Questions\n",
    "\n",
    "**To make sure your code produces consistent results, it is advisable to click \"Kernel -> Restart & Run All\" every time you want to run your code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d88fe0d5a5da473",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 1: CNN Advantage (10 points)\n",
    "\n",
    "Compute the accuracy of a simple dense neural network and a simple CNN on the dataset. Explain the results and briefly overview the advantages of a CNN over a standard neural network for image-related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-90d19f37b669e57c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "The accuracy of a simple dense neural network on the dataset is 42.12%, while the accuracy of a simple CNN on the dataset is 68.66%. The difference in these results (with that of the CNN performing better) is unsurprising, since a simple dense neural network would not be able to incorporate special input structures (such as kernels) needed for learning features from image data, whereas the CNN has these provisions. Flatting the image matrix and feeding it into the simple dense neural network causes the loss of spatial structures depicted in the images, which are better parsed by a CNN which connects patches of image pixels to neurons instead. Moreover, flattening the image into 1D vectors as in the case of the simple dense neural network increases the number of parameters, making the process computationally intensive. The CNN can automatically extract the spatial features from the images, whereas in the case of a dense neural network, the data points related to the image must be explicity provided, making it a cumbersome choice for image data. However, in this case, the results of the CNN leave a lot to be desired and can likely be improved further with some data augmentation and/or hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ff132f3e79a9ae46",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2: Dropout Rate (25 points)\n",
    "\n",
    "Explain the purpose of dropout in any neural network model. In doing so, note what can happen if the dropout rate is too high and what can happen if the dropout rate is too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1d4aaf9724eff071",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Neural network models tend to overfit the training dataset, leading to poor generalization on the test dataset. To overcome this, some neurons are randomly dropped out during training in the process known as Dropout, which effectively makes it equivalent to training several different neural networks. This simulates neural network model averaging so that the model doesn't rely on just one configuration of neurons to make a prediction.\n",
    "\n",
    "If the dropout rate is too high, most of the neurons would get dropped resulting in a slow convergence rate of the model and suboptimal model performance. If the dropout rate is too low, the purpose of its usage (i.e. to prevent overfitting) is lost as it would result in suboptimal improvements in generalization capabilities since the model configuration would be not too different from the original one. Therefore, dropout rates need to be tuned for each layer and each training stage, or are ideally kept between 0.5 and 0.8 for most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e05305cff2c7415f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3: Kernel Size (25 points)\n",
    "\n",
    "Explain the purpose of spatial filters (kernels) in a CNN. Additionally, explain where they fit into the overall architecture of the CNN in this coding example. Finally, explain what can happen if the kernel size is too large and what can happen if the kernel size is too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5bd1497e584129ea",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Spatial filters (kernels) in a CNN are used in extracting features (such as edges, corners, etc.) from images and provide important signals to computer vision prediction tasks. They are essentially matrices that slide over the input data and provide output matrices of dot products with the input data. The kernels share their parameters spatially.\n",
    "\n",
    "Within the overall architecture of the CNN, kernels are generally associated with non-linearities (such as the ReLU function) and are interspersed with pooling layers to downsample the activation maps while preserving the spatial structures, followed by fully-connected layers for the output prediction. \n",
    "\n",
    "A very large kernel size may detect global features but misses out on the finer, local features. Morever, it increases the computational time taken for model training. A very small kernel size, on the other hand, has the consequence of extracting features which would be extremely fine-grained and local with lack of information from neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42306086a7bdf4e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4: Data Augmentation (40 points)\n",
    "\n",
    "Use the code snippet provided in the next box to implement data augmentation by updating the contents of box 3 and re-running the model. Compare your accuracy without and with data augmentation and explain the results. In doing so, explain the purpose of data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef28cafc520fc2a3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomRotation(degrees=[-5.0, 5.0], interpolation=nearest, expand=False, fill=0),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.RandomRotation(5),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ea6c603cd9e5a90a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "With data augmentation, the accuracy of a simple dense neural network on the dataset is 41.68%, while the accuracy of a simple CNN on the dataset is 68.23%.\n",
    "\n",
    "Without data augmentation, the accuracy of a simple dense neural network on the dataset is 42.12%, while the accuracy of a simple CNN on the dataset is 68.66%.\n",
    "\n",
    "In both cases, the CNN performs better than the simple dense neural network. However, clearly, compared to the results without data augmentation, the accuracy of both models with data augmentation have reduced slightly. This is likely due to the small data size, batch size, computational limit, and/or lack of further variations in data augmentation.\n",
    "\n",
    "In general, data augmentation is used to augment the training data with artificially generated data involving the transformation of the input data (in this case, images) such that the original class label of this data is preserved. The number and variety of images in the training data can be increased by multiple techniques such as rotation, cropping, blurring, flipping, etc. In this case, only Random Rotation was used. Data augmentation is typically done so that the model can become more robust in identifying the diverse features and nuances of the training data, which would prevent it from memorizing the training data and overfitting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
